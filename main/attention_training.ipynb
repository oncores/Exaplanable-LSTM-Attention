{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from preprocessing.input_data_index_embedding import *\n",
    "\n",
    "from preprocessing.preprocessing_code_190418 import title_catcher, preprocess, date_process\n",
    "import pickle as pkl\n",
    "import re\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_score, recall_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from collections import Counter\n",
    "from konlpy.tag import Komoran\n",
    "from eunjeon import Mecab\n",
    "mecab = Mecab()\n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Input, Embedding, Dense, LSTM, Bidirectional, Dropout, Concatenate, Flatten, Conv1D, Conv2D, GlobalMaxPooling1D, TimeDistributed, SpatialDropout1D, GRU, multiply, Lambda, Reshape, CuDNNGRU, CuDNNLSTM, Permute, RepeatVector, Multiply\n",
    "from keras.layers import MaxPool1D\n",
    "from keras.models import Model, Sequential\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import Adam\n",
    "from keras.engine.topology import Layer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras_self_attention import SeqSelfAttention\n",
    "from keras import regularizers\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import Activation\n",
    "import seaborn as sn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../data/191203_인수계약서_최종.xlsx'\n",
    "vocab_to_int_dir = '../preprocessing/insu_vocab_to_int.pkl'\n",
    "int_to_vocab_dir = '../preprocessing/insu_int_to_vocab.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./par_model/train_probability.pickle', 'rb') as f:\n",
    "    train_prob = pickle.load(f)\n",
    "with open('./par_model/valid_probability.pickle', 'rb') as f:\n",
    "    valid_prob = pickle.load(f)\n",
    "with open('./par_model/test_probability.pickle', 'rb') as f:\n",
    "    test_prob = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>par_id</th>\n",
       "      <th>art_id</th>\n",
       "      <th>line_id</th>\n",
       "      <th>text</th>\n",
       "      <th>par_label</th>\n",
       "      <th>line_label</th>\n",
       "      <th>split_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>제1조 (정의)</td>\n",
       "      <td>정의</td>\n",
       "      <td>-</td>\n",
       "      <td>22_정의</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>본 계약에서 사용하는 용어는 다음과 같은 뜻을 가진다.</td>\n",
       "      <td>정의</td>\n",
       "      <td>PR-02-01</td>\n",
       "      <td>22_정의</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1. \"인수단\"은 \"대표주관회사\" 및 \"인수회사\"를 말한다.</td>\n",
       "      <td>정의</td>\n",
       "      <td>PR-02-02</td>\n",
       "      <td>22_정의</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   doc_id  par_id  art_id  line_id                               text  \\\n",
       "0      22       2       1        0                           제1조 (정의)   \n",
       "1      22       2       1        1     본 계약에서 사용하는 용어는 다음과 같은 뜻을 가진다.   \n",
       "2      22       2       1        2  1. \"인수단\"은 \"대표주관회사\" 및 \"인수회사\"를 말한다.   \n",
       "\n",
       "  par_label line_label split_id  \n",
       "0        정의          -    22_정의  \n",
       "1        정의   PR-02-01    22_정의  \n",
       "2        정의   PR-02-02    22_정의  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "origin_data = load_dataset(data_dir)\n",
    "origin_data = join_date(origin_data)\n",
    "origin_data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document to paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>doc</th>\n",
       "      <th>label</th>\n",
       "      <th>line_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0                                             ...</td>\n",
       "      <td>정의</td>\n",
       "      <td>[-, PR-02-01, PR-02-02, PR-02-03, PR-02-04, PR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>19                                        제2조 ...</td>\n",
       "      <td>인수_및_모집</td>\n",
       "      <td>[-, PR-03-01, PR-03-02, PR-03-02, PR-03-02, PR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>32                                   제3조 (\"본 사...</td>\n",
       "      <td>본_사채의_발행조건</td>\n",
       "      <td>[-, PR-04-03, PR-04-04, PR-04-05, PR-04-06, PR...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                                doc       label  \\\n",
       "0      0  0                                             ...          정의   \n",
       "1      1  19                                        제2조 ...     인수_및_모집   \n",
       "2      2  32                                   제3조 (\"본 사...  본_사채의_발행조건   \n",
       "\n",
       "                                          line_label  \n",
       "0  [-, PR-02-01, PR-02-02, PR-02-03, PR-02-04, PR...  \n",
       "1  [-, PR-03-01, PR-03-02, PR-03-02, PR-03-02, PR...  \n",
       "2  [-, PR-04-03, PR-04-04, PR-04-05, PR-04-06, PR...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ptl_df = document_label_dataset_training(origin_data)\n",
    "ptl_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(x_all):  5202\n",
      "len(y_all):  5202\n",
      "len(x_train):  3641\n",
      "len(y_train):  3641\n",
      "len(x_valid):  780\n",
      "len(y_valid):  780\n",
      "len(x_test):  781\n",
      "len(y_test):  781\n"
     ]
    }
   ],
   "source": [
    "x_all, y_all, x_train, y_train, x_valid, y_valid, x_test, y_test, matrix_train, matrix_valid, matrix_test = split_newdataset_sw(ptl_df, 'index', 1103)\n",
    "print('len(x_all): ', len(x_all))\n",
    "print('len(y_all): ', len(y_all))\n",
    "print('len(x_train): ', len(x_train))\n",
    "print('len(y_train): ', len(y_train))\n",
    "print('len(x_valid): ', len(x_valid))\n",
    "print('len(y_valid): ', len(y_valid))\n",
    "print('len(x_test): ', len(x_test))\n",
    "print('len(y_test): ', len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_class = np.unique(origin_data['line_label'].values)\n",
    "class_size = len(valid_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab_to_int, int_to_vocab = bow_vocab(x_train, vocab_to_int_dir, int_to_vocab_dir)\n",
    "vocab_to_int, int_to_vocab = load_bow_vocab(vocab_to_int_dir, int_to_vocab_dir)\n",
    "# max_len, max_row, mean_len, mean_row = max_length(x_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 350\n",
    "max_row = 121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_len 350\n",
      "max_row 121\n"
     ]
    }
   ],
   "source": [
    "print('max_len', max_len)\n",
    "print('max_row', max_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# index_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_par_class = np.unique(np.concatenate([i.split(',') for i in np.unique(ptl_df['label'].values)]))\n",
    "parlabel_to_int = bow_label(unique_par_class)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#각 문단의 행 번호\n",
    "train_row = tagging_row_index(x_train)\n",
    "valid_row = tagging_row_index(x_valid)\n",
    "test_row = tagging_row_index(x_test)\n",
    "\n",
    "train_row_ = row_embed(train_row, max_row)\n",
    "valid_row_ = row_embed(valid_row, max_row)\n",
    "test_row_ = row_embed(test_row, max_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_type = 'model'\n",
    "# col_type = 'answer'\n",
    "\n",
    "if col_type == 'model' :\n",
    "    #각 문단의 열 번호\n",
    "    train_proba = np.concatenate([[train_prob[num] for cnt in x_train[num]] for num in range(len(x_train))])\n",
    "    valid_proba = np.concatenate([[valid_prob[num] for cnt in x_valid[num]] for num in range(len(x_valid))])\n",
    "    test_proba = np.concatenate([[test_prob[num] for cnt in x_test[num]] for num in range(len(x_test))])\n",
    "    \n",
    "elif col_type == 'answer':\n",
    "    #multi_label을 위해 comma 기준으로 split\n",
    "    split_matrix_train = [[labels.split(',') for labels in par] for par in matrix_train]\n",
    "    split_matrix_valid = [[labels.split(',') for labels in par] for par in matrix_valid]\n",
    "    split_matrix_test = [[labels.split(',') for labels in par] for par in matrix_test]\n",
    "    \n",
    "    #각 문단의 열 번호\n",
    "    train_proba = np.concatenate([[labels_to_vecs(labels, unique_par_class, parlabel_to_int) for labels in par] for par in split_matrix_train])\n",
    "    valid_proba = np.concatenate([[labels_to_vecs(labels, unique_par_class, parlabel_to_int) for labels in par] for par in split_matrix_valid])\n",
    "    test_proba = np.concatenate([[labels_to_vecs(labels, unique_par_class, parlabel_to_int) for labels in par] for par in split_matrix_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train_ :  (43139, 350)\n",
      "y_train_ :  (43139, 250)\n",
      "\n",
      "x_valid_ :  (9540, 350)\n",
      "x_valid_ :  (9540, 250)\n",
      "\n",
      "x_test_ :  (9775, 350)\n",
      "y_test_ :  (9775, 250)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_train_ = x_data_set(x_train, max_len, vocab_to_int)\n",
    "y_train_ = y_data_set(y_train, valid_class, max_row)\n",
    "\n",
    "x_valid_ = x_data_set(x_valid, max_len, vocab_to_int)\n",
    "y_valid_ = y_data_set(y_valid, valid_class, max_row)\n",
    "\n",
    "x_test_ = x_data_set(x_test, max_len, vocab_to_int)\n",
    "y_test_ = y_data_set(y_test, valid_class, max_row)\n",
    "\n",
    "# y_all_ = y_data_set(y_all, valid_class, max_row)\n",
    "\n",
    "print('x_train_ : ', x_train_.shape)\n",
    "print('y_train_ : ', y_train_.shape, end='\\n\\n')\n",
    "\n",
    "print('x_valid_ : ', x_valid_.shape)\n",
    "print('x_valid_ : ', y_valid_.shape, end='\\n\\n')\n",
    "\n",
    "print('x_test_ : ', x_test_.shape)\n",
    "print('y_test_ : ', y_test_.shape, end='\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hyper parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper Parameter\n",
    "\n",
    "n_words = len(int_to_vocab) + 2\n",
    "embed_size = 100\n",
    "\n",
    "batch_size = 8\n",
    "learning_rate = 0.0001\n",
    "epochs = 500\n",
    "\n",
    "sentence_wise_lstm_size = 128\n",
    "\n",
    "dense_dropout = 0.5\n",
    "l2_reg = regularizers.l2(0.0001)\n",
    "\n",
    "dense_size = 128\n",
    "attention_dim = 100\n",
    "rnn_dim = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionLayer(Layer):\n",
    "    def __init__(self, attention_dim, **kwargs):\n",
    "        self.attention_dim = attention_dim\n",
    "        super(AttentionLayer, self).__init__(**kwargs)\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        self.W = self.add_weight(name='Attention_Weight',\n",
    "                                 shape=(input_shape[-1], self.attention_dim),\n",
    "                                 initializer='random_normal',\n",
    "                                 trainable=True)\n",
    "        self.b = self.add_weight(name='Attention_Bias',\n",
    "                                 shape=(self.attention_dim, ),\n",
    "                                 initializer='random_normal',\n",
    "                                 trainable=True)\n",
    "        self.u = self.add_weight(name='Attention_Context_Vector',\n",
    "                                 shape=(self.attention_dim, 1),\n",
    "                                 initializer='random_normal',\n",
    "                                 trainable=True)\n",
    "        super(AttentionLayer, self).build(input_shape)\n",
    "        \n",
    "    def call(self, x):\n",
    "        # refer to the original paper\n",
    "        # link: https://www.cs.cmu.edu/~hovy/papers/16HLT-hierarchical-attention-networks.pdf\n",
    "        u_it = K.tanh(K.dot(x, self.W) + self.b)\n",
    "        a_it = K.dot(u_it, self.u)\n",
    "        a_it = K.squeeze(a_it, -1)\n",
    "        a_it = K.softmax(a_it)\n",
    "        return a_it\n",
    "        \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], input_shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def WeightedSum(attentions, representations):\n",
    "    # from Shape(batch_size, len_units) to Shape(batch_size, rnn_dim * 2, len_units)\n",
    "    # RepeatVector는 인풋을 lstm output의 마지막 차원만큼 반복하는 함수\n",
    "    repeated_attentions = RepeatVector(K.int_shape(representations)[-1])(attentions)\n",
    "    \n",
    "    # from Shape(batch_size, rnn_dim * 2, len_units) to Shape(batch_size, len_units, lstm_dim * 2)\n",
    "    # 입력의 1차원과 2차원을 치환한다.\n",
    "    repeated_attentions = Permute([2, 1])(repeated_attentions)\n",
    "    \n",
    "    # compute representation as the weighted sum of representations\n",
    "    # \n",
    "    aggregated_representation = Multiply()([representations, repeated_attentions])\n",
    "    aggregated_representation = Lambda(lambda x: K.sum(x, axis=1))(aggregated_representation)\n",
    "    \n",
    "    return aggregated_representation\n",
    "\n",
    "def SenWeightedSum(attentions, representations):\n",
    "    # from Shape(batch_size, len_units) to Shape(batch_size, rnn_dim * 2, len_units)\n",
    "    repeated_attentions = RepeatVector(K.int_shape(representations)[-1])(attentions)\n",
    "\n",
    "    # from Shape(batch_size, rnn_dim * 2, len_units) to Shape(batch_size, len_units, lstm_dim * 2)\n",
    "    repeated_attentions = Permute([2, 1])(repeated_attentions)\n",
    "    \n",
    "    # compute representation as the weighted sum of representations\n",
    "    aggregated_representation = Multiply()([representations, repeated_attentions])\n",
    "#     aggregated_representation = TimeDistributed(Lambda(lambda x: K.sum(x, axis=1)))(aggregated_representation)\n",
    "\n",
    "    return aggregated_representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 문단정보반영모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TabSen():\n",
    "    \n",
    "    K.clear_session()\n",
    "    np.random.seed(1201)\n",
    "    \n",
    "    ##### index model using dense_layer #####\n",
    "    row_embed = Input(shape = (max_row, ), name = 'row_input')\n",
    "    col_embed = Input(shape = (len(unique_par_class), ), name = 'col_input')\n",
    "    \n",
    "    row_layer = Dense(128)(row_embed)\n",
    "    col_layer = Dense(128)(col_embed)\n",
    "    \n",
    "    ##### word model using lstm #####\n",
    "    word_inp_embed = Input(shape = (None, ), name = 'word_input')\n",
    "    word_embed = Embedding(n_words, embed_size, trainable = True)(word_inp_embed)    \n",
    "    \n",
    "    lstm = Bidirectional(CuDNNLSTM(sentence_wise_lstm_size, return_sequences=True))(word_embed)\n",
    "    lstm_bn = BatchNormalization()(lstm)\n",
    "    \n",
    "    attn_score = AttentionLayer(attention_dim)(lstm_bn)\n",
    "    attn_out = WeightedSum(attn_score, lstm_bn)\n",
    "    \n",
    "    ##### concat lstm_layer,row,col #####\n",
    "    concat = Concatenate()([attn_out, row_layer, col_layer])\n",
    "\n",
    "    ##### fully connected layers #####\n",
    "\n",
    "    fc_layer = Dense(dense_size, \n",
    "                  activation='relu', \n",
    "                  kernel_regularizer = keras.regularizers.l2(1e-5), \n",
    "                  bias_regularizer = keras.regularizers.l1(1e-3))(concat)\n",
    "    dropout = Dropout(dense_dropout)(fc_layer)    \n",
    "    output = Dense(class_size, activation = 'softmax')(dropout)\n",
    "    \n",
    "    model = Model(inputs = [word_inp_embed, row_embed, col_embed], outputs = output)\n",
    "    \n",
    "    word_attention_extractor = Model(inputs=[word_inp_embed],\n",
    "                                     outputs=[attn_score])\n",
    "    \n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer = Adam(learning_rate), metrics = ['accuracy'])\n",
    "    return model, word_attention_extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\jeon\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:107: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\jeon\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:111: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\jeon\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\jeon\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\jeon\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\jeon\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Users\\jeon\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "word_input (InputLayer)         (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 100)    181000      word_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, None, 256)    235520      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, None, 256)    1024        bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "attention_layer_1 (AttentionLay (None, None)         25800       batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_1 (RepeatVector)  (None, 256, None)    0           attention_layer_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "permute_1 (Permute)             (None, None, 256)    0           repeat_vector_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, None, 256)    0           batch_normalization_1[0][0]      \n",
      "                                                                 permute_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "row_input (InputLayer)          (None, 121)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "col_input (InputLayer)          (None, 29)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 256)          0           multiply_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          15616       row_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 128)          3840        col_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 512)          0           lambda_1[0][0]                   \n",
      "                                                                 dense_1[0][0]                    \n",
      "                                                                 dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 128)          65664       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 128)          0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 250)          32250       dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 560,714\n",
      "Trainable params: 560,202\n",
      "Non-trainable params: 512\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "checkpoint = ModelCheckpoint('../weight/attention/{epoch:02d}-{val_loss:.4f}.hdf5', save_best_only=True, verbose=1)\n",
    "tabsen, word_attention_extractor = TabSen()\n",
    "tabsen.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tabsen_hist = tabsen.fit(\n",
    "#                 x=[x_train_, train_row_, train_proba],\n",
    "#                 y=y_train_,\n",
    "#                 batch_size=16,\n",
    "#                 epochs=50,\n",
    "#                 verbose=True,\n",
    "#                 validation_data=([x_valid_, valid_row_, valid_proba], y_valid_),\n",
    "#                 callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "fig.patch.set_facecolor('xkcd:white')\n",
    "plt.plot(tabsen_hist.history[\"loss\"])\n",
    "plt.plot(tabsen_hist.history[\"val_loss\"])\n",
    "plt.legend(['train','valid'])\n",
    "# plt.xlim(100,500)\n",
    "# plt.ylim(0.0,0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "fig.patch.set_facecolor('xkcd:white')\n",
    "plt.plot(tabsen_hist.history[\"acc\"])\n",
    "plt.plot(tabsen_hist.history[\"val_acc\"])\n",
    "plt.legend(['train','valid'])\n",
    "# plt.xlim(100,500)\n",
    "# plt.ylim(0.0,0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tabsen.load_weights('../weight/attention/33-0.1379.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy : 0.9781867915343425\n",
      "valid accuracy : 0.9832285115303984\n",
      "test accuracy : 0.9840409207161125\n"
     ]
    }
   ],
   "source": [
    "train_accuracy = print('train accuracy : {}'.format(evaluate(input_data=[x_train_, train_row_, train_proba], real=y_train_, model=tabsen)))\n",
    "valid_accuracy = print('valid accuracy : {}'.format(evaluate(input_data=[x_valid_, valid_row_, valid_proba], real=y_valid_, model=tabsen)))\n",
    "test_accuracy = print('test accuracy : {}'.format(evaluate(input_data=[x_test_, test_row_, test_proba], real=y_test_, model=tabsen)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_score(real, input_data, model):\n",
    "    pred_data = model.predict(input_data)\n",
    "    pred_label = [np.argmax(i) for i in pred_data]\n",
    "    real_label = [np.argmax(i) for i in real]\n",
    "    \n",
    "    score = precision_recall_fscore_support(real_label, pred_label)\n",
    "    mean_score = [np.mean(i) for i in score[0:3]]\n",
    "    \n",
    "    return mean_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision : 0.9663731787962756\n",
      "recall : 0.9604724861055559\n",
      "fscore : 0.9618698016864959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jeon\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "precision, recall, fscore = metric_score(real=y_train_, input_data=[x_train_, train_row_, train_proba], model=tabsen)\n",
    "print('precision : {}'.format(precision))\n",
    "print('recall : {}'.format(recall))\n",
    "print('fscore : {}'.format(fscore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision : 0.9617282679615882\n",
      "recall : 0.9602516973049949\n",
      "fscore : 0.959414724122534\n"
     ]
    }
   ],
   "source": [
    "precision, recall, fscore = metric_score(real=y_valid_, input_data=[x_valid_, valid_row_, valid_proba], model=tabsen)\n",
    "print('precision : {}'.format(precision))\n",
    "print('recall : {}'.format(recall))\n",
    "print('fscore : {}'.format(fscore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision : 0.968243589866517\n",
      "recall : 0.960829685199897\n",
      "fscore : 0.9622844275427626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jeon\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "precision, recall, fscore = metric_score(real=y_test_, input_data=[x_test_, test_row_, test_proba], model=tabsen)\n",
    "print('precision : {}'.format(precision))\n",
    "print('recall : {}'.format(recall))\n",
    "print('fscore : {}'.format(fscore))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 해석 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## variable_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_to_vocab[0] = 'pad'\n",
    "int_to_vocab[1] = 'UNK'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.font_manager as fm\n",
    "fm.get_fontconfig_fonts()\n",
    "font_location = 'C:/Windows/Fonts/malgun.ttf' # For Windows\n",
    "font_name = fm.FontProperties(fname=font_location).get_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_x_dict = {}\n",
    "init_x_dict['train'] = x_train_\n",
    "init_x_dict['valid'] = x_valid_\n",
    "init_x_dict['test'] = x_test_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_y_dict = {}\n",
    "init_y_dict['train'] = y_train_\n",
    "init_y_dict['valid'] = y_valid_\n",
    "init_y_dict['test'] = y_test_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hst_output(output):\n",
    "    return [vecs2labels((line_output>threshold)*1, int_to_label) for line_output in output]\n",
    "\n",
    "def vecs2labels(vecs, int_to_label):\n",
    "    output = []\n",
    "    for i, vec in enumerate(vecs):\n",
    "        if vec == 1:\n",
    "            output.append(int_to_label[i])\n",
    "    return output    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## attention extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_int, int_to_label = bow_label(valid_class)\n",
    "pred_attention = word_attention_extractor.predict(init_x_dict[split])\n",
    "labels = [int_to_label[np.argmax(i)] for i in init_y_dict['test']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_list = []\n",
    "for sent_idx, sentence in enumerate(init_x_dict[split]):\n",
    "    if sentence[0] == 0:\n",
    "        continue\n",
    "\n",
    "    for word_idx in range(max_len):\n",
    "        if sentence[word_idx] == 0:\n",
    "            words = [int_to_vocab[word_id] for word_id in sentence[0:word_idx]]\n",
    "            pred_att = pred_attention[sent_idx][0:len(words)]\n",
    "            pred_att = np.expand_dims(pred_att, axis=0)\n",
    "            break\n",
    "            \n",
    "    fig, ax = plt.subplots(figsize=(len(words), 1))\n",
    "    plt.rc('font', family=font_name)\n",
    "    plt.rc('xtick', labelsize=12)\n",
    "    midpoint = (max(pred_att[:, 0]) - min(pred_att[:, 0])) / 2\n",
    "    heatmap = sn.heatmap(pred_att, xticklabels=words, yticklabels=False, square=True, linewidths=0.1, cmap='coolwarm', center=midpoint, vmin=0, vmax=1)\n",
    "    words_list.append([np.array(pred_att[0]), words, labels[sent_idx]])\n",
    "    \n",
    "#     print(pred_att)\n",
    "#     print(words)\n",
    "#     print(labels[sent_idx])\n",
    "#     print(line_dict[labels[sent_idx][0]])\n",
    "\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.title(line_dict[labels[sent_idx][0]],)\n",
    "\n",
    "    fig = plt.gcf()\n",
    "    fig.savefig('./output_png/200128/word_attention_{}_{}'.format(split,sent_idx), bbox_inches = \"tight\")\n",
    "    fig = plt.figure()\n",
    "    fig.patch.set_facecolor('xkcd:white')\n",
    "    plt.show()\n",
    "    print('*************************************************')\n",
    "    print('\\n\\n\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = [i[0] for i in words_list]\n",
    "tokens = [i[1] for i in words_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sen_idx, (score,token) in enumerate(zip(scores, tokens)) :\n",
    "    for tok_idx, (s,t) in enumerate(zip(score, token)) :\n",
    "        print(t, ':', s)\n",
    "    df = pd.DataFrame(score,token).T\n",
    "    df.to_excel('./output_excel/0121_answer/output_{}_{}.xlsx'.format(split, sen_idx))\n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count Per Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def int_to_label(y_vectors, valid_class):\n",
    "    enc = OneHotEncoder(handle_unknown='ignore')\n",
    "    enc.fit(valid_class.reshape(-1,1))\n",
    "    labels = enc.inverse_transform(y_vectors)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_per_label(input_data, real, seg, output):\n",
    "    pred = tabsen.predict(input_data)\n",
    "    pred_label = [line_dict[i] for i in np.concatenate(int_to_label(pred, valid_class))]\n",
    "    real_label = [line_dict[i] for i in np.concatenate(int_to_label(real, valid_class))]\n",
    "    accuracy = [[pred==real, real] for pred, real in zip(pred_label, real_label)]\n",
    "    \n",
    "    count_real_label = pd.DataFrame([i for i in Counter(real_label).items()])\n",
    "    count_real_label.columns = ['label','count']\n",
    "\n",
    "    accuracy = pd.DataFrame(accuracy).groupby([1]).mean().reset_index()\n",
    "    accuracy.columns = ['label', 'accuracy']\n",
    "    \n",
    "    df = pd.merge(count_real_label, accuracy)\n",
    "    \n",
    "    if output==True :    \n",
    "        df.to_excel('./result/output_result_{}.xlsx'.format(seg))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_index = pd.read_excel('../data/index_line_label.xlsx', header=None)\n",
    "line_dict = {}\n",
    "for i in line_index.values:\n",
    "#     print(i[1])\n",
    "    line_dict[i[1]] = i[0]\n",
    "line_dict['-'] = '-'    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = count_per_label(input_data=[x_train_, train_row_, train_proba], real=y_train_, seg='train', output=True)\n",
    "valid_df = count_per_label(input_data=[x_valid_, valid_row_, valid_proba], real=y_valid_, seg='valid', output=True)\n",
    "test_df = count_per_label(input_data=[x_test_, test_row_, test_proba], real=y_test_, seg='test', output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_data(input_data, real, seg, output):\n",
    "    pred = tabsen.predict(input_data)\n",
    "    pred_label = [line_dict[i] for i in np.concatenate(int_to_label(pred, valid_class))]\n",
    "    real_label = [line_dict[i] for i in np.concatenate(int_to_label(real, valid_class))]\n",
    "    accuracy = [[pred==real, real] for pred, real in zip(pred_label, real_label)]\n",
    "    \n",
    "    count_real_label = pd.DataFrame([i for i in Counter(real_label).items()])\n",
    "    count_real_label.columns = ['label',seg]\n",
    "\n",
    "    return count_real_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_count_df = count_data(input_data=[x_train_, train_row_, train_proba], real=y_train_, seg='train', output=True)\n",
    "valid_count_df = count_data(input_data=[x_valid_, valid_row_, valid_proba], real=y_valid_, seg='valid', output=True)\n",
    "test_count_df = count_data(input_data=[x_test_, test_row_, test_proba], real=y_test_, seg='test', output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_count_df = pd.merge(pd.merge(train_count_df, valid_count_df, on='label', how='outer'), test_count_df, on='label', how='outer').to_excel('./result/output_all_count.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
